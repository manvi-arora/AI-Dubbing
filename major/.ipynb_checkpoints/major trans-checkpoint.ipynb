{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "[MoviePy] Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3675/3675 [00:01<00:00, 2546.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AudioFileClip' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3fc4618318c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0maudio_output_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'temp_audio.wav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mextract_audio_from_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio_output_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_text_from_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mrecognizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-3fc4618318c6>\u001b[0m in \u001b[0;36mextract_audio_from_video\u001b[1;34m(video_path, audio_output_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0maudio_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_clip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0maudio_clip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_audiofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_output_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0maudio_clip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mvideo_clip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AudioFileClip' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "\n",
    "def extract_audio_from_video(video_path, audio_output_path):\n",
    "    video_clip = mp.VideoFileClip(video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(audio_output_path)\n",
    "    audio_clip.close()\n",
    "    video_clip.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = 'sample.mp4'\n",
    "    audio_output_path = 'temp_audio.wav'\n",
    "\n",
    "    extract_audio_from_video(video_path, audio_output_path)\n",
    "def extract_text_from_audio(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        extracted_text = recognizer.recognize_google(audio)\n",
    "        return extracted_text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech Recognition could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_path = 'temp_audio.wav'\n",
    "\n",
    "    extracted_text = extract_text_from_audio(audio_path)\n",
    "\n",
    "    # Save the extracted text to a TXT file\n",
    "    with open('extracted_text.txt', 'w') as txt_file:\n",
    "        txt_file.write(extracted_text)\n",
    "\n",
    "    print(\"Text extracted and saved to extracted_text.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LibsndfileError",
     "evalue": "Error opening 'D:\\\\STUDY\\\\SEMESTER 7\\\\PROJECT\\\\sample.mp4': Format not recognised.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32md:\\STUDY\\SEMESTER 7\\PROJECT\\1.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/PROJECT/1.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Convert video to audio\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/PROJECT/1.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m audio_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtemp_audio.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/PROJECT/1.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m torchaudio\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mResample(orig_freq\u001b[39m=\u001b[39m\u001b[39m44100\u001b[39m, new_freq\u001b[39m=\u001b[39m\u001b[39m16000\u001b[39m)(sf\u001b[39m.\u001b[39;49mread(video_path)[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/PROJECT/1.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m sf\u001b[39m.\u001b[39mwrite(audio_path, y, \u001b[39m16000\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/PROJECT/1.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Load pretrained model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\soundfile.py:285\u001b[0m, in \u001b[0;36mread\u001b[1;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(file, frames\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, start\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, stop\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m'\u001b[39m, always_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    200\u001b[0m          fill_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, samplerate\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, channels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    201\u001b[0m          \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, subtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, endian\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, closefd\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    202\u001b[0m     \u001b[39m\"\"\"Provide audio data from a sound file as NumPy array.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \n\u001b[0;32m    204\u001b[0m \u001b[39m    By default, the whole file is read from the beginning, but the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m \n\u001b[0;32m    284\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mwith\u001b[39;00m SoundFile(file, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, samplerate, channels,\n\u001b[0;32m    286\u001b[0m                    subtype, endian, \u001b[39mformat\u001b[39;49m, closefd) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    287\u001b[0m         frames \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39m_prepare_read(start, stop, frames)\n\u001b[0;32m    288\u001b[0m         data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread(frames, dtype, always_2d, fill_value, out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m file_ptr \u001b[39m==\u001b[39m _ffi\u001b[39m.\u001b[39mNULL:\n\u001b[0;32m   1214\u001b[0m     \u001b[39m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mframes \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'D:\\\\STUDY\\\\SEMESTER 7\\\\PROJECT\\\\sample.mp4': Format not recognised."
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import pipeline\n",
    "\n",
    "video_path = 'D:\\STUDY\\SEMESTER 7\\PROJECT\\sample.mp4'\n",
    "output_txt_path = 'extracted_text.txt'\n",
    "\n",
    "# Convert video to audio\n",
    "audio_path = 'temp_audio.wav'\n",
    "torchaudio.transforms.Resample(orig_freq=44100, new_freq=16000)(sf.read(video_path)[0]).numpy()\n",
    "sf.write(audio_path, y, 16000)\n",
    "\n",
    "# Load pretrained model\n",
    "generator = torch.hub.load('snakers4/silero-models', 'silero_stt', lang='en')\n",
    "\n",
    "# Perform speech-to-text\n",
    "transcriptions = generator(audio_path)\n",
    "\n",
    "# Save extracted text to TXT file\n",
    "with open(output_txt_path, 'w') as txt_file:\n",
    "    txt_file.write(transcriptions[0]['text'])\n",
    "\n",
    "print(f\"Text extracted and saved to {output_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted and saved to output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "video_path = 'D:\\STUDY\\SEMESTER 7\\PROJECT\\sample.mp4'\n",
    "output_audio_path = 'output_audio.wav'\n",
    "\n",
    "# Load the video using moviepy\n",
    "video_clip = VideoFileClip(video_path)\n",
    "\n",
    "# Extract audio using PyDub\n",
    "audio = video_clip.audio\n",
    "audio.write_audiofile(output_audio_path)\n",
    "\n",
    "print(f\"Audio extracted and saved to {output_audio_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\STUDY\\SEMESTER 7\\PROJECT\\1.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/PROJECT/1.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m speech_v1p1beta1 \u001b[39mas\u001b[39;00m speech\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/PROJECT/1.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m audio_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39moutput_audio.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/PROJECT/1.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m output_txt_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39moutput_text.txt\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "\n",
    "audio_path = 'output_audio.wav'\n",
    "output_txt_path = 'output_text.txt'\n",
    "\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "with open(audio_path, \"rb\") as audio_file:\n",
    "    content = audio_file.read()\n",
    "\n",
    "audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code=\"en-US\",\n",
    ")\n",
    "\n",
    "response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "with open(output_txt_path, 'w') as txt_file:\n",
    "    for result in response.results:\n",
    "        txt_file.write(result.alternatives[0].transcript + '\\n')\n",
    "\n",
    "print(f\"Text extracted and saved to {output_txt_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

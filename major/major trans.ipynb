{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Video as the input and extracting audio and text from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "MoviePy error: failed to read the duration of file \"D:/STUDY/SEMESTER 7/NATURAL LANGUAGE PROCESSING/The World Through the Eyes of Animals.mp4\".\nHere are the file infos returned by ffmpeg:\n\nffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\r\n  built with gcc 9.2.1 (GCC) 20200122\r\n  configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\r\n  libavutil      56. 31.100 / 56. 31.100\r\n  libavcodec     58. 54.100 / 58. 54.100\r\n  libavformat    58. 29.100 / 58. 29.100\r\n  libavdevice    58.  8.100 / 58.  8.100\r\n  libavfilter     7. 57.100 /  7. 57.100\r\n  libswscale      5.  5.100 /  5.  5.100\r\n  libswresample   3.  5.100 /  3.  5.100\r\n  libpostproc    55.  5.100 / 55.  5.100\r\n\"D:/STUDY/SEMESTER 7/NATURAL LANGUAGE PROCESSING/The World Through the Eyes of Animals.mp4\": Invalid argument\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:285\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    284\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m is_GIF \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 285\u001b[0m line \u001b[39m=\u001b[39m [l \u001b[39mfor\u001b[39;49;00m l \u001b[39min\u001b[39;49;00m lines \u001b[39mif\u001b[39;49;00m keyword \u001b[39min\u001b[39;49;00m l][index]\n\u001b[0;32m    286\u001b[0m match \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39m\"\u001b[39m\u001b[39m([0-9][0-9]:[0-9][0-9]:[0-9][0-9].[0-9][0-9])\u001b[39m\u001b[39m\"\u001b[39m, line)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\STUDY\\SEMESTER 7\\NATURAL LANGUAGE PROCESSING\\Project\\major\\major trans.ipynb Cell 2\u001b[0m line \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/NATURAL%20LANGUAGE%20PROCESSING/Project/major/major%20trans.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m video_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mD:/STUDY/SEMESTER 7/NATURAL LANGUAGE PROCESSING/The World Through the Eyes of Animals.mp4\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/NATURAL%20LANGUAGE%20PROCESSING/Project/major/major%20trans.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m audio_output_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39moutput.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/NATURAL%20LANGUAGE%20PROCESSING/Project/major/major%20trans.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m extract_audio_from_video(video_path, audio_output_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/NATURAL%20LANGUAGE%20PROCESSING/Project/major/major%20trans.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mextracted audio\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\STUDY\\SEMESTER 7\\NATURAL LANGUAGE PROCESSING\\Project\\major\\major trans.ipynb Cell 2\u001b[0m line \u001b[0;36mextract_audio_from_video\u001b[1;34m(video_path, audio_output_path)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/NATURAL%20LANGUAGE%20PROCESSING/Project/major/major%20trans.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_audio_from_video\u001b[39m(video_path, audio_output_path):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/NATURAL%20LANGUAGE%20PROCESSING/Project/major/major%20trans.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     video_clip \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39;49mVideoFileClip(video_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/NATURAL%20LANGUAGE%20PROCESSING/Project/major/major%20trans.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     audio_clip \u001b[39m=\u001b[39m video_clip\u001b[39m.\u001b[39maudio\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/STUDY/SEMESTER%207/NATURAL%20LANGUAGE%20PROCESSING/Project/major/major%20trans.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     audio_clip\u001b[39m.\u001b[39mwrite_audiofile(audio_output_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:88\u001b[0m, in \u001b[0;36mVideoFileClip.__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39m# Make a reader\u001b[39;00m\n\u001b[0;32m     87\u001b[0m pix_fmt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgba\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m has_mask \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrgb24\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader \u001b[39m=\u001b[39m FFMPEG_VideoReader(filename, pix_fmt\u001b[39m=\u001b[39;49mpix_fmt,\n\u001b[0;32m     89\u001b[0m                                  target_resolution\u001b[39m=\u001b[39;49mtarget_resolution,\n\u001b[0;32m     90\u001b[0m                                  resize_algo\u001b[39m=\u001b[39;49mresize_algorithm,\n\u001b[0;32m     91\u001b[0m                                  fps_source\u001b[39m=\u001b[39;49mfps_source)\n\u001b[0;32m     93\u001b[0m \u001b[39m# Make some of the reader's attributes accessible from the clip\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mduration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mduration\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:35\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m filename\n\u001b[0;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproc \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m infos \u001b[39m=\u001b[39m ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[0;32m     36\u001b[0m                            fps_source)\n\u001b[0;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfps \u001b[39m=\u001b[39m infos[\u001b[39m'\u001b[39m\u001b[39mvideo_fps\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m infos[\u001b[39m'\u001b[39m\u001b[39mvideo_size\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:289\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    287\u001b[0m         result[\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m cvsecs(match)\n\u001b[0;32m    288\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m((\u001b[39m\"\u001b[39m\u001b[39mMoviePy error: failed to read the duration of file \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mHere are the file infos returned by ffmpeg:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m%\u001b[39m(\n\u001b[0;32m    291\u001b[0m                           filename, infos))\n\u001b[0;32m    293\u001b[0m \u001b[39m# get the output line that speaks about video\u001b[39;00m\n\u001b[0;32m    294\u001b[0m lines_video \u001b[39m=\u001b[39m [l \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lines \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m Video: \u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m l \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+x\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m, l)]\n",
      "\u001b[1;31mOSError\u001b[0m: MoviePy error: failed to read the duration of file \"D:/STUDY/SEMESTER 7/NATURAL LANGUAGE PROCESSING/The World Through the Eyes of Animals.mp4\".\nHere are the file infos returned by ffmpeg:\n\nffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\r\n  built with gcc 9.2.1 (GCC) 20200122\r\n  configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt\r\n  libavutil      56. 31.100 / 56. 31.100\r\n  libavcodec     58. 54.100 / 58. 54.100\r\n  libavformat    58. 29.100 / 58. 29.100\r\n  libavdevice    58.  8.100 / 58.  8.100\r\n  libavfilter     7. 57.100 /  7. 57.100\r\n  libswscale      5.  5.100 /  5.  5.100\r\n  libswresample   3.  5.100 /  3.  5.100\r\n  libpostproc    55.  5.100 / 55.  5.100\r\n\"D:/STUDY/SEMESTER 7/NATURAL LANGUAGE PROCESSING/The World Through the Eyes of Animals.mp4\": Invalid argument\r\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "\n",
    "def extract_audio_from_video(video_path, audio_output_path):\n",
    "    video_clip = mp.VideoFileClip(video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(audio_output_path)\n",
    "    audio_clip.close()\n",
    "    video_clip.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = '1.mp4'\n",
    "    audio_output_path = 'output.wav'\n",
    "    extract_audio_from_video(video_path, audio_output_path)\n",
    "    print(\"extracted audio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Audio to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1 transcription saved\n",
      "Segment 2 transcription saved\n",
      "Segment 3 transcription saved\n",
      "Segment 4 transcription saved\n",
      "Segment 5 transcription saved\n",
      "Segment 6 transcription saved\n",
      "Segment 7 transcription saved\n",
      "Segment 8 transcription saved\n",
      "Segment 9 transcription saved\n",
      "Segment 10 transcription saved\n",
      "Segment 11 transcription saved\n",
      "Segment 12 transcription saved\n",
      "Segment 13 transcription saved\n",
      "Segment 14 transcription saved\n",
      "Segment 15 transcription saved\n",
      "Segment 16 transcription saved\n",
      "Segment 17 transcription saved\n",
      "Segment 18 transcription saved\n",
      "Segment 19 transcription saved\n",
      "Segment 20 transcription saved\n",
      "Segment 21 transcription saved\n",
      "Segment 22 transcription saved\n",
      "Segment 23 transcription saved\n",
      "Segment 24 transcription saved\n",
      "Segment 25 transcription saved\n",
      "Segment 26 transcription saved\n",
      "Segment 27 transcription saved\n",
      "Segment 28 transcription saved\n",
      "Segment 29 transcription saved\n",
      "Segment 30 transcription saved\n",
      "Segment 31 transcription saved\n",
      "Segment 32 transcription saved\n",
      "Segment 33 transcription saved\n",
      "Segment 34 transcription saved\n",
      "Segment 35 transcription saved\n",
      "Segment 36 transcription saved\n",
      "Segment 37 transcription saved\n",
      "Segment 38 transcription saved\n",
      "Segment 39 transcription saved\n",
      "Segment 40 transcription saved\n",
      "Segment 41 transcription saved\n",
      "Segment 42 transcription saved\n",
      "Segment 43 transcription saved\n",
      "Segment 44 transcription saved\n",
      "Segment 45 transcription saved\n",
      "Segment 46 transcription saved\n",
      "Segment 47 transcription saved\n",
      "Segment 48 transcription saved\n",
      "Segment 49 transcription saved\n",
      "Segment 50: Google Web Speech API could not understand the audio\n",
      "Combined transcription saved to output_segments\\combined_transcription.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Function to split audio into segments and transcribe each segment\n",
    "def transcribe_audio_segments(audio_file_path, output_folder):\n",
    "    # Initialize the recognizer\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "\n",
    "    # Duration of each segment in milliseconds (adjust as needed)\n",
    "    segment_duration_ms = 5000  # 5 seconds\n",
    "\n",
    "    # Calculate the number of segments\n",
    "    num_segments = len(audio) // segment_duration_ms + 1\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # List to store segment transcriptions\n",
    "    segment_transcriptions = []\n",
    "\n",
    "    # Process and transcribe each segment\n",
    "    for i in range(num_segments):\n",
    "        start_time = i * segment_duration_ms\n",
    "        end_time = (i + 1) * segment_duration_ms\n",
    "\n",
    "        # Extract the segment\n",
    "        segment = audio[start_time:end_time]\n",
    "\n",
    "        # Transcribe the segment using Google Web Speech API\n",
    "        try:\n",
    "            # Export the segment as a temporary WAV file\n",
    "            temp_audio_file = os.path.join(output_folder, f\"segment_{i}.wav\")\n",
    "            segment.export(temp_audio_file, format=\"wav\")\n",
    "\n",
    "            # Recognize the segment\n",
    "            with sr.AudioFile(temp_audio_file) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio_data)\n",
    "\n",
    "            # Append the transcription to the list\n",
    "            segment_transcriptions.append(text)\n",
    "\n",
    "            print(f\"Segment {i + 1} transcription saved\")\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(f\"Segment {i + 1}: Google Web Speech API could not understand the audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Segment {i + 1}: Could not request results from Google Web Speech API; {e}\")\n",
    "\n",
    "    # Combine all segment transcriptions into one text file\n",
    "    combined_text = \"\\n\".join(segment_transcriptions)\n",
    "    combined_output_file = os.path.join(output_folder, \"combined_transcription.txt\")\n",
    "\n",
    "    with open(combined_output_file, 'w') as txt_file:\n",
    "        txt_file.write(combined_text)\n",
    "\n",
    "    print(f\"Combined transcription saved to {combined_output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_audio_file = \"output.wav\"  # Replace with the path to your input audio file\n",
    "    output_folder = \"output_segments\"  # Replace with the desired output folder\n",
    "\n",
    "    transcribe_audio_segments(input_audio_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take extracted text as input and translate it to Traget language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install deep-translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text translation to gujarati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation saved to translated_text.txt\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import re\n",
    "\n",
    "# Function to split text into chunks with a maximum number of words\n",
    "def split_text_by_words(text, max_words_per_chunk):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        if len(' '.join(current_chunk)) + len(word) <= max_words_per_chunk:\n",
    "            current_chunk.append(word)\n",
    "        else:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Function to translate a list of text chunks and combine them\n",
    "def translate_and_combine(input_text, source_language, target_language, max_words_per_chunk):\n",
    "    try:\n",
    "        # Split the input text into chunks by words\n",
    "        text_chunks = split_text_by_words(input_text, max_words_per_chunk)\n",
    "\n",
    "        # Initialize an empty list to store translated chunks\n",
    "        translated_chunks = []\n",
    "\n",
    "        # Translate each chunk and store the translations\n",
    "        for chunk in text_chunks:\n",
    "            translation = GoogleTranslator(source=source_language, target=target_language).translate(chunk)\n",
    "            translated_chunks.append(translation)\n",
    "\n",
    "        # Combine the translated chunks into a single string\n",
    "        translated_text = ' '.join(translated_chunks)\n",
    "\n",
    "        return translated_text\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "# Read input text from a file (replace 'input.txt' with your file path)\n",
    "with open('output_segments/combined_transcription.txt', 'r', encoding='utf-8') as input_file:\n",
    "    input_text = input_file.read()\n",
    "\n",
    "source_language = 'auto'  # Auto-detect source language\n",
    "target_language = 'gu'  # Gujarati\n",
    "max_words_per_chunk = 5000  # Maximum words per chunk\n",
    "\n",
    "# Remove extra spaces, tabs, and line breaks from the input text\n",
    "input_text = ' '.join(input_text.split())\n",
    "\n",
    "# Translate and combine the text\n",
    "translated_text = translate_and_combine(input_text, source_language, target_language, max_words_per_chunk)\n",
    "\n",
    "# Write the translated text to a file\n",
    "with open('translated_text.txt', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(translated_text)\n",
    "\n",
    "print(\"Translation saved to translated_text.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from transformers import pipeline\\nimport textwrap\\n\\n# Load the text summarization model\\nsummarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\\n\\n# Read the input text from a file\\nwith open(\\'output_segments/combined_transcription.txt\\', \\'r\\', encoding=\\'utf-8\\') as file:\\n    input_text = file.read()\\n\\n# Split the input text into smaller chunks\\nmax_chunk_length = 1000  # Adjust this value as needed\\nchunks = textwrap.wrap(input_text, width=max_chunk_length)\\n\\n# Initialize an empty summary\\ncombined_summary = \"\"\\n\\n# Summarize each chunk and append to the combined summary\\nfor chunk in chunks:\\n    summary = summarizer(chunk, max_length=150, min_length=100, do_sample=False)[0][\\'summary_text\\']\\n    combined_summary += summary + \"\\n\"\\n\\n# Print the combined summarized text\\nprint(combined_summary)\\n\\n# Save the combined summarized text to an output file\\nwith open(\\'summary.txt\\', \\'w\\', encoding=\\'utf-8\\') as file:\\n    file.write(combined_summary)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import textwrap\n",
    "\n",
    "# Load the text summarization model\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "# Read the input text from a file\n",
    "with open('output_segments/combined_transcription.txt', 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Split the input text into smaller chunks\n",
    "max_chunk_length = 1000  # Adjust this value as needed\n",
    "chunks = textwrap.wrap(input_text, width=max_chunk_length)\n",
    "\n",
    "# Initialize an empty summary\n",
    "combined_summary = \"\"\n",
    "\n",
    "# Summarize each chunk and append to the combined summary\n",
    "for chunk in chunks:\n",
    "    summary = summarizer(chunk, max_length=150, min_length=100, do_sample=False)[0]['summary_text']\n",
    "    combined_summary += summary + \"\\n\"\n",
    "\n",
    "# Print the combined summarized text\n",
    "print(combined_summary)\n",
    "\n",
    "# Save the combined summarized text to an output file\n",
    "with open('summary.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(combined_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install gTTS wavio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to output2.wav\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "# Function to convert text to audio and save as a WAV file\n",
    "def text_to_audio(input_file_path, output_audio_file_path, language='gu'):\n",
    "    try:\n",
    "        # Read Gujarati text from the input .txt file\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "            gujarati_text = file.read()\n",
    "\n",
    "        # Initialize a gTTS object with the Gujarati text and language code\n",
    "        tts = gTTS(text=gujarati_text, lang=language)\n",
    "\n",
    "        # Save the generated audio as a WAV file\n",
    "        tts.save(output_audio_file_path)\n",
    "\n",
    "        print(f\"Audio saved to {output_audio_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the path to your input .txt file containing Gujarati text\n",
    "    input_file_path = \"translated_text.txt\"  \n",
    "\n",
    "    # Define the path for saving the output audio as a WAV file\n",
    "    output_audio_file_path = \"output2.wav\" \n",
    "\n",
    "    # Convert Gujarati text to audio and save as a WAV file\n",
    "    text_to_audio(input_file_path, output_audio_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install Flask moviepy pydub SpeechRecognition deep_translator transformers pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting pyttsx3\n",
      "  Using cached pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Collecting comtypes (from pyttsx3)\n",
      "  Obtaining dependency information for comtypes from https://files.pythonhosted.org/packages/c2/a7/fe4bd49b5c4afa7a7ed3852abda6909e48c00715e6a134e47055381113aa/comtypes-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading comtypes-1.2.0-py2.py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pypiwin32 (from pyttsx3)\n",
      "  Using cached pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\manvi\\appdata\\roaming\\python\\python310\\site-packages (from pyttsx3) (303)\n",
      "Downloading comtypes-1.2.0-py2.py3-none-any.whl (184 kB)\n",
      "   ---------------------------------------- 184.3/184.3 kB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: comtypes, pypiwin32, pyttsx3\n",
      "Successfully installed comtypes-1.2.0 pypiwin32-223 pyttsx3-2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\manvi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\manvi\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     -------------------------------------- 981.5/981.5 kB 6.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\manvi\\appdata\\roaming\\python\\python310\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=c6f00272063a4b5bfd71ffba8754fdb0836a9da6f99ea6d598dd4a7123b1a777\n",
      "  Stored in directory: c:\\users\\manvi\\appdata\\local\\pip\\cache\\wheels\\95\\03\\7d\\59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\manvi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\manvi\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to output2.mp3\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "# Function to convert Gujarati text from a .txt file to audio\n",
    "def text_to_audio(input_text_file, output_audio_file):\n",
    "    try:\n",
    "        # Read the Gujarati text from the input .txt file\n",
    "        with open(input_text_file, 'r', encoding='utf-8') as file:\n",
    "            input_text = file.read()\n",
    "\n",
    "        # Create a gTTS (Google Text-to-Speech) object for Gujarati\n",
    "        tts = gTTS(text=input_text, lang='gu')\n",
    "\n",
    "        # Save the generated audio as a .mp3 file (or specify another format)\n",
    "        tts.save(output_audio_file)\n",
    "\n",
    "        print(f\"Audio saved to {output_audio_file}\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the path to your input .txt file containing Gujarati text\n",
    "    input_text_file_path = \"translated_text.txt\"  # Replace with your input .txt file path\n",
    "\n",
    "    # Define the path for saving the output audio file (in .mp3 format)\n",
    "    output_audio_file_path = \"output2.mp3\"  # Replace with your desired output audio file path\n",
    "\n",
    "    # Convert Gujarati text from the .txt file to audio\n",
    "    text_to_audio(input_text_file_path, output_audio_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video.mp4.\n",
      "MoviePy - Writing audio in output_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n",
      "Synchronized video saved to output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "\n",
    "# Function to synchronize dubbed audio with a video\n",
    "def sync_audio_with_video(original_video_path, dubbed_audio_path, output_video_path):\n",
    "    try:\n",
    "        # Load the original video\n",
    "        video_clip = mp.VideoFileClip(original_video_path)\n",
    "\n",
    "        # Load the dubbed audio\n",
    "        dubbed_audio_clip = mp.AudioFileClip(dubbed_audio_path)\n",
    "\n",
    "        # Set the video's audio to the dubbed audio\n",
    "        video_clip = video_clip.set_audio(dubbed_audio_clip)\n",
    "\n",
    "        # Write the synchronized video with audio to the output file\n",
    "        video_clip.write_videofile(output_video_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "        print(f\"Synchronized video saved to {output_video_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the paths to your original video, dubbed audio, and the output video\n",
    "    original_video_path = \"1.mp4\"  # Replace with your original video file path\n",
    "    dubbed_audio_path = \"output2.mp3\"  # Replace with your dubbed audio file path\n",
    "    output_video_path = \"output_video.mp4\"  # Replace with your desired output video file path\n",
    "\n",
    "    # Synchronize dubbed audio with the original video\n",
    "    sync_audio_with_video(original_video_path, dubbed_audio_path, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, send_file, flash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
